{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dbd0147c-7890-4c49-a9d8-937b57c5778d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Notebook 02 — Feature Engineering (Silver & Gold Layers)\n",
    "\n",
    "This notebook performs the feature engineering steps required to prepare the dataset\n",
    "for machine learning. The transformations follow a standard Databricks/Spark ML workflow.\n",
    "\n",
    "### Steps:\n",
    "- Load Bronze table\n",
    "- Identify categorical and numerical features\n",
    "- Clean categorical values (\"NA\" → \"unknown\")\n",
    "- Apply StringIndexer + OneHotEncoder\n",
    "- Normalize numerical features\n",
    "- Assemble final feature vector\n",
    "- Generate Silver and Gold Delta tables\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "07c8bbb4-b3ee-4e71-b53e-6787b4b3639e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Load Bronze Table\n",
    "\n",
    "Read the Bronze Delta table generated in Notebook 01.  \n",
    "This table contains standardized raw data ready for feature engineering.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3bc780ef-e638-4e8d-bb6d-df9d74a0f5be",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_bronze = spark.read.format(\"delta\").load(\n",
    "    \"dbfs:/Volumes/workspace/credit-risk/credit-risk/bronze\"\n",
    ")\n",
    "\n",
    "df_bronze.display()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f5110e1b-14ca-42f3-9859-ffa67ed6a055",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Identify Feature Types\n",
    "\n",
    "Programmatically detect categorical (string) and numerical (int/double) columns.\n",
    "This keeps the pipeline dynamic and schema-driven.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7ae6b98b-375c-495a-9488-9f3d0d16b457",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "categorical_cols = [c for c, t in df_bronze.dtypes if t == \"string\"]\n",
    "numeric_cols = [c for c, t in df_bronze.dtypes if t in [\"int\", \"double\"]]\n",
    "\n",
    "categorical_cols, numeric_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "011a40c4-aec2-4c91-bdc4-39ac0851e9e5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Clean Categorical Values\n",
    "\n",
    "Replace invalid category tokens (\"NA\") with a consistent placeholder (\"unknown\").\n",
    "This avoids value explosion during indexing and prevents model bias.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "53d643b0-b0a6-4e19-ba27-673549986712",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when\n",
    "\n",
    "df_fixed = df_bronze\n",
    "\n",
    "cols_with_na = [\"saving_accounts\", \"checking_account\"]\n",
    "\n",
    "for col_name in cols_with_na:\n",
    "    df_fixed = df_fixed.withColumn(\n",
    "        col_name,\n",
    "        when(df_fixed[col_name] == \"NA\", \"unknown\").otherwise(df_fixed[col_name])\n",
    "    )\n",
    "\n",
    "df_fixed.display()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "343024e3-bcf1-4544-accb-5f4c00ce6945",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Encode Categorical Features\n",
    "\n",
    "Use:\n",
    "- StringIndexer → categorical string → numerical index  \n",
    "- OneHotEncoder → index → sparse vector  \n",
    "\n",
    "This prevents the model from interpreting categories as ordinal.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "448c6c9e-ff67-4ff3-ba9c-7619befb89b9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "indexers = [\n",
    "    StringIndexer(\n",
    "        inputCol=c,\n",
    "        outputCol=f\"{c}_idx\",\n",
    "        handleInvalid=\"keep\"\n",
    "    )\n",
    "    for c in categorical_cols\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5e1355fb-d63b-449e-a4d7-350252b29e8b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import OneHotEncoder\n",
    "\n",
    "encoder = OneHotEncoder(\n",
    "    inputCols=[f\"{c}_idx\" for c in categorical_cols],\n",
    "    outputCols=[f\"{c}_ohe\" for c in categorical_cols]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d8e22cfe-c6a4-46d1-9d7a-8858a86b83ce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Normalize Numerical Features\n",
    "\n",
    "Assemble all numerical columns into a single vector and normalize them using MinMaxScaler.  \n",
    "This ensures numerical values share a similar range before model training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dddce6cd-8fc3-4acd-805f-ece24d695ded",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler, MinMaxScaler\n",
    "\n",
    "numeric_assembler = VectorAssembler(\n",
    "    inputCols=numeric_cols,\n",
    "    outputCol=\"numeric_vector\"\n",
    ")\n",
    "\n",
    "scaler = MinMaxScaler(\n",
    "    inputCol=\"numeric_vector\",\n",
    "    outputCol=\"numeric_scaled\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f341eb92-3098-42e1-88ab-10e59a074115",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Assemble Final Feature Vector\n",
    "\n",
    "Concatenate all encoded categorical vectors and the normalized numeric vector into the \n",
    "`features` column used by Spark ML models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b0435335-db9f-4d2c-b508-c4b7a1c0093d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "final_features = [f\"{c}_ohe\" for c in categorical_cols] + [\"numeric_scaled\"]\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=final_features,\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "621bf4c6-b2ee-4825-9c9d-d509a6c5e252",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Fit Pipeline & Generate Gold Table\n",
    "\n",
    "Fit the end-to-end transformation pipeline and produce:\n",
    "- Silver table (cleaned & indexed)\n",
    "- Gold table (fully encoded feature matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "58f23c7c-17c7-41fa-bc31-d74e756646a3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    stages=indexers + [encoder, numeric_assembler, scaler, assembler]\n",
    ")\n",
    "\n",
    "model = pipeline.fit(df_fixed)\n",
    "df_gold = model.transform(df_fixed)\n",
    "\n",
    "df_gold.display()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a5cecc73-fdfe-4965-a0e7-d77990267455",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Save Silver & Gold Tables\n",
    "\n",
    "Persist the engineered tables in Delta format for downstream model training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "73544712-77f1-40cb-a3bf-04013889a144",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_fixed.write.format(\"delta\").mode(\"overwrite\").save(\n",
    "    \"dbfs:/Volumes/workspace/credit-risk/credit-risk/silver\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fcfb7172-3e37-455f-a516-96000981e431",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_gold.write.format(\"delta\").mode(\"overwrite\").save(\n",
    "    \"dbfs:/Volumes/workspace/credit-risk/credit-risk/gold\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fe655d3b-13d8-4038-8c92-c3de27178434",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_gold.display()\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "02_feature_engineering",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
