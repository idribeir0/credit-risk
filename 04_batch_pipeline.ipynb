{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "515e2427-bf5b-428a-83cb-053d6a799357",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when, col\n",
    "from pyspark.ml.feature import (\n",
    "    StringIndexer, OneHotEncoder, VectorAssembler, MinMaxScaler\n",
    ")\n",
    "from pyspark.ml import Pipeline\n",
    "import mlflow\n",
    "import mlflow.spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "04071135-6698-4547-a26d-010f1a570f49",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_raw = spark.read.csv(\n",
    "    \"dbfs:/Volumes/workspace/credit-risk/credit-risk/german_credit_data.csv\",\n",
    "    header=True,\n",
    "    inferSchema=True\n",
    ")\n",
    "\n",
    "df_raw.display()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0159dfe1-f006-43cc-8daa-3d1ddb95ce4e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def bronze_layer(df):\n",
    "    # Drop index column if it exists\n",
    "    if \"_c0\" in df.columns:\n",
    "        df = df.drop(\"_c0\")\n",
    "    \n",
    "    # Normalize column names\n",
    "    df = df.toDF(*[\n",
    "        c.lower().replace(\" \", \"_\").replace(\"-\", \"_\").replace(\"/\", \"_\")\n",
    "        for c in df.columns\n",
    "    ])\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0620d056-b6f3-4306-bdd0-588193cb9a42",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_bronze = bronze_layer(df_raw)\n",
    "df_bronze.display()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d4805bcf-1f66-4b45-91a1-a9d148612791",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def silver_layer(df):\n",
    "    cols_with_na = [\"saving_accounts\", \"checking_account\"]\n",
    "\n",
    "    for col_name in cols_with_na:\n",
    "        if col_name in df.columns:\n",
    "            df = df.withColumn(\n",
    "                col_name,\n",
    "                when(col(col_name) == \"NA\", \"unknown\").otherwise(col(col_name))\n",
    "            )\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e51dfe20-eb35-4624-aac5-9bbfe3ed1640",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_silver = silver_layer(df_bronze)\n",
    "df_silver.display()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7efec93b-3c89-4b3c-8dc1-f132899e15da",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def gold_layer(df):\n",
    "    # Identify columns\n",
    "    categorical_cols = [c for c, t in df.dtypes if t == \"string\"]\n",
    "    numeric_cols = [c for c, t in df.dtypes if t in [\"int\", \"double\"]]\n",
    "\n",
    "    # Index categorical columns\n",
    "    indexers = [\n",
    "        StringIndexer(inputCol=c, outputCol=f\"{c}_idx\", handleInvalid=\"keep\")\n",
    "        for c in categorical_cols\n",
    "    ]\n",
    "\n",
    "    # One-hot encode indexed columns\n",
    "    encoder = OneHotEncoder(\n",
    "        inputCols=[f\"{c}_idx\" for c in categorical_cols],\n",
    "        outputCols=[f\"{c}_ohe\" for c in categorical_cols]\n",
    "    )\n",
    "\n",
    "    # Assemble numeric columns\n",
    "    numeric_assembler = VectorAssembler(\n",
    "        inputCols=numeric_cols,\n",
    "        outputCol=\"numeric_vector\"\n",
    "    )\n",
    "\n",
    "    # Normalize numeric vector\n",
    "    scaler = MinMaxScaler(\n",
    "        inputCol=\"numeric_vector\",\n",
    "        outputCol=\"numeric_scaled\"\n",
    "    )\n",
    "\n",
    "    # Final features\n",
    "    final_features = [f\"{c}_ohe\" for c in categorical_cols] + [\"numeric_scaled\"]\n",
    "\n",
    "    assembler = VectorAssembler(\n",
    "        inputCols=final_features,\n",
    "        outputCol=\"features\"\n",
    "    )\n",
    "\n",
    "    # Pipeline\n",
    "    pipeline = Pipeline(\n",
    "        stages=indexers + [encoder, numeric_assembler, scaler, assembler]\n",
    "    )\n",
    "    model = pipeline.fit(df)\n",
    "    transformed = model.transform(df)\n",
    "\n",
    "    return transformed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "31616195-906c-45bd-b530-63e67f02dee9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_gold = gold_layer(df_silver)\n",
    "df_gold.display()\n",
    "df_gold.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9a3d7bc2-ccdc-4c13-aaf6-9a29a11c833d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "best_model_path = \"/Volumes/workspace/credit-risk/credit-risk/models/best_model\"\n",
    "best_model = mlflow.spark.load_model(best_model_path)\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "04_batch_pipeline",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
